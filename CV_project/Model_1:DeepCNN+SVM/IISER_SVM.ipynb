{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Functions to load and pre-process the images:\n",
    "from skimage.io import imread\n",
    "from skimage import img_as_ubyte\n",
    "from sigver.preprocessing.normalize import preprocess_signature\n",
    "\n",
    "# Functions to load the CNN model\n",
    "from sigver.featurelearning.models import SigNet\n",
    "\n",
    "# Functions for plotting:\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load signature\n",
    "def load_signature(path):\n",
    "    return img_as_ubyte(imread(path, as_gray=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of signatures with key as user number\n",
    "user_sigs = {}\n",
    "for i in range(1, 35):\n",
    "    user_sigs[i]= [load_signature('data/IISER_Genuine/Genuine/{}-G-{}.jpg'.format(i, j)) for j in  [1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39443/2267855104.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343904639/work/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  processed_user_sigs[i] = torch.tensor([preprocess_signature(sig, canvas_size_iiser) for sig in user_sigs[i]])\n"
     ]
    }
   ],
   "source": [
    "# Create dictionary of preprocessed signatures with key as user number\n",
    "processed_user_sigs = {}\n",
    "canvas_size_iiser = (5000, 5000)\n",
    "for i in range(1, 35):\n",
    "    processed_user_sigs[i] = torch.tensor([preprocess_signature(sig, canvas_size_iiser) for sig in user_sigs[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to appropriate dimensions, and divide by 255 to convert intensities to the range [0, 1]\n",
    "for i in range(1, 35):\n",
    "    processed_user_sigs[i] = processed_user_sigs[i].view(-1, 1, 150, 220).float().div(255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the CNN to obtain the feature representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# If GPU is available, use it:\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "state_dict, _, _ = torch.load('models/signet.pth')\n",
    "base_model = SigNet().to(device).eval()\n",
    "base_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each image to its feature vector representation using the pretrained model.\n",
    "user_features = {}\n",
    "with torch.no_grad():\n",
    "    for i in range(1, 35):\n",
    "        user_features[i] = base_model(processed_user_sigs[i].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dimensions of the vector. It should be a 248-dimensional vecotr\n",
    "user_features[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form the dataset and labels using the feature vectors. The labels are the user numbers from 1 to 34.\n",
    "X = []\n",
    "y = []\n",
    "for i in range(1, 35):\n",
    "    for j in range(3):\n",
    "        X.append(np.array(user_features[i][j]))\n",
    "        y.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 2048)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "# Convert the lists to numpy arrays\n",
    "X = np.vstack(X)\n",
    "print(X.shape)\n",
    "y = np.array(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/susheel/anaconda3/envs/sigver/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.15, 'class_weight': None, 'coef0': 0.0, 'degree': 2, 'gamma': 0.01, 'kernel': 'linear', 'shrinking': True}\n",
      "Best Model Accuracy: 0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "# Use GridSearch to obtain best hyperparameters of SVM classifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid you want to search\n",
    "param_grid = {\n",
    "    'C': [0.15, 0.2, 0.25, 0.3],  # Different values for the regularization parameter\n",
    "    'kernel': ['linear', 'rbf'],  # Kernel function\n",
    "    'gamma': [0.01, 0.1, 1],  # Kernel coefficient for 'rbf' kernel\n",
    "    'degree': [2, 3, 4],  # Degree of the polynomial kernel\n",
    "    'coef0': [0.0, 1.0],  # Independent term in kernel function\n",
    "    'shrinking': [True, False],  # Whether to use shrinking heuristic\n",
    "    'class_weight': [None, 'balanced'],  # Class weights\n",
    "}\n",
    "\n",
    "# Create an SVM classifier\n",
    "svc = SVC()\n",
    "\n",
    "# Create a GridSearchCV object with cross-validation\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=3)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(best_params)\n",
    "\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_classifier.predict(X_test)\n",
    "\n",
    "accuracy = best_classifier.score(X_test, y_test)\n",
    "print(f'Best Model Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7745098039215687\n"
     ]
    }
   ],
   "source": [
    "# Compute mean accuracy using Leave One Out cross validation\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Create an SVM classifier \n",
    "clf = SVC(C=0.2, kernel='linear', gamma=0.2, degree=2, shrinking=True)\n",
    "\n",
    "# Initialize LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Initialize variables to store results\n",
    "accuracies = []\n",
    "\n",
    "# Perform LOOCV\n",
    "for train_index, test_index in loo.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculate the mean accuracy over all iterations\n",
    "mean_accuracy = sum(accuracies) / len(accuracies)\n",
    "print(f\"Mean Accuracy: {mean_accuracy}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sigver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
